{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "X93SodzAv9hV"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/robocarstore/donkey-car-training-on-google-colab/blob/master/Donkey_Car_Training_using_Google_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlmQIFSLZDdc"
      },
      "source": [
        "# Donkey Car Training using Google Colab\n",
        "\n",
        "Train your donkey car model using accelerated GPU for FREE on Google Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arsH-DhLcihq"
      },
      "source": [
        "## Check GPU and Tensorflow version\n",
        "If \"Found GPU at: / device: GPU: 0\" is displayed, the GPU is ready to use."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "ORYT2sEa9Vx1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verified tensorflow version: > 2.9 and <= 2.15"
      ],
      "metadata": {
        "id": "Xf2CZgLm9gGk"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQgEhuoTcg0N"
      },
      "source": [
        "import tensorflow\n",
        "print(tensorflow.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ba2oPDIrsDFg"
      },
      "source": [
        "## Git Clone the donkey repository"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOxd9PFUyNxI"
      },
      "source": [
        "!git clone https://github.com/robocarstore/donkeycar.git\n",
        "%cd /content/donkeycar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git checkout v5"
      ],
      "metadata": {
        "id": "u6nZMEOSmBy3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9TkkcF-gsAnx"
      },
      "source": [
        "## Install donkey car"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip3 install --upgrade pip setuptools wheel\n",
        "!pip3 install -e .[pc]"
      ],
      "metadata": {
        "id": "bhfs7OmMlXYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syCctLq2r4Wk"
      },
      "source": [
        "## Create Project"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xjJBSITyXy2"
      },
      "source": [
        "!donkey createcar --path /content/mycar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W47gmXA0O4Lo"
      },
      "source": [
        "### Download your dataset\n",
        "\n",
        "You can download your dataset to this Colab instance by the following command. You might obtain the uuid of the dataset from the meta.json under each tub."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/mycar/data\n",
        "!curl  -O -J \"https://robocarstore-dc-sg.s3.amazonaws.com/tubs/63783f2f-9497-460b-a6ad-3607c20dcbff/data.tar.gz\"\n"
      ],
      "metadata": {
        "id": "22t7txjxCKld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfSDpXj9x16v"
      },
      "source": [
        "Use the following command to extract the dataset into a folder named tub_xxxxxxx"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urhFWBkUyGf0"
      },
      "source": [
        "!tar -xzf data.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!curl  -O -J \"https://robocarstore-dc-sg.s3.amazonaws.com/tubs/19007878-6909-4c46-b6da-59e95355b15a/data.tar.gz\"\n",
        "!tar -xzf data.tar.gz\n",
        "!rm data.tar.gz"
      ],
      "metadata": {
        "id": "dyyFNr_KC8xp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "f4GCu9keDzmV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assuming the latest created folder is the tub_name."
      ],
      "metadata": {
        "id": "4F40oA10DSnL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tub_name=!ls -td -- */ | head -n 1\n",
        "tub_name = tub_name[0].strip('/')\n",
        "tub_name"
      ],
      "metadata": {
        "id": "QCNXdA7GCaKg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyPsgV5KyFkg"
      },
      "source": [
        "Check whether the data is there"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsItvBTkzWcH"
      },
      "source": [
        "!ls {tub_name}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check number of images in this tub"
      ],
      "metadata": {
        "id": "gyskUezgrSUH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/mycar/data/{tub_name}\n",
        "!find . -type f -name \"*.jpg\" | wc -l"
      ],
      "metadata": {
        "id": "UjFMR-rRrC-m",
        "outputId": "43068a4b-8cc5-4448-dead-2199453f0b35",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/mycar/data/tub_49_24-01-13\n",
            "6623\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate a movie for preview"
      ],
      "metadata": {
        "id": "oOnUjZaBELYY"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AZvWSeiyqto",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9515d0e-18f6-4450-f530-e69fab8fa5fc"
      },
      "source": [
        "!pip uninstall keras-vis\n",
        "!pip install git+https://github.com/sctse999/keras-vis\n",
        "\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping keras-vis as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting git+https://github.com/sctse999/keras-vis\n",
            "  Cloning https://github.com/sctse999/keras-vis to /tmp/pip-req-build-8grlag6v\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/sctse999/keras-vis /tmp/pip-req-build-8grlag6v\n",
            "  Resolved https://github.com/sctse999/keras-vis to commit 93e1e803dc0779e25f95b6c1e871d499414e5404\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from keras-vis==0.5.0) (1.16.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from keras-vis==0.5.0) (0.19.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from keras-vis==0.5.0) (3.7.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras-vis==0.5.0) (3.9.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from h5py->keras-vis==0.5.0) (1.23.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->keras-vis==0.5.0) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->keras-vis==0.5.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->keras-vis==0.5.0) (4.47.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->keras-vis==0.5.0) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->keras-vis==0.5.0) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->keras-vis==0.5.0) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->keras-vis==0.5.0) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->keras-vis==0.5.0) (2.8.2)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->keras-vis==0.5.0) (1.11.4)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->keras-vis==0.5.0) (3.2.1)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->keras-vis==0.5.0) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->keras-vis==0.5.0) (2023.12.9)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->keras-vis==0.5.0) (1.5.0)\n",
            "Building wheels for collected packages: keras-vis\n",
            "  Building wheel for keras-vis (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-vis: filename=keras_vis-0.5.0-py2.py3-none-any.whl size=30956 sha256=9e9222a99b8a759813da80613ef716d63a9e441f96c06a3d415e543b2db3aecb\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-mzbrhzn7/wheels/76/f4/c7/79f07c4e592d76b0adc5dc32b610988e36a56e8d288d286612\n",
            "Successfully built keras-vis\n",
            "Installing collected packages: keras-vis\n",
            "Successfully installed keras-vis-0.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/mycar\n",
        "!donkey makemovie --tub ./data/{tub_name} --out {tub_name}.mp4 --start 1 --end 2000"
      ],
      "metadata": {
        "id": "_G0VMYJ_tCCP",
        "outputId": "deca0241-5872-45ee-f0c3-beb87ea1a7b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/mycar\n",
            "________             ______                   _________              \n",
            "___  __ \\_______________  /___________  __    __  ____/_____ ________\n",
            "__  / / /  __ \\_  __ \\_  //_/  _ \\_  / / /    _  /    _  __ `/_  ___/\n",
            "_  /_/ // /_/ /  / / /  ,<  /  __/  /_/ /     / /___  / /_/ /_  /    \n",
            "/_____/ \\____//_/ /_//_/|_| \\___/_\\__, /      \\____/  \\__,_/ /_/     \n",
            "                                 /____/                              \n",
            "\n",
            "using donkey v5.0.dev3 ...\n",
            "error: XDG_RUNTIME_DIR not set in the environment.\n",
            "ALSA lib confmisc.c:855:(parse_card) cannot find card '0'\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_card_inum returned error: No such file or directory\n",
            "ALSA lib confmisc.c:422:(snd_func_concat) error evaluating strings\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\n",
            "ALSA lib confmisc.c:1334:(snd_func_refer) error evaluating name\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n",
            "ALSA lib conf.c:5701:(snd_config_expand) Evaluate error: No such file or directory\n",
            "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM default\n",
            "ALSA lib confmisc.c:855:(parse_card) cannot find card '0'\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_card_inum returned error: No such file or directory\n",
            "ALSA lib confmisc.c:422:(snd_func_concat) error evaluating strings\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\n",
            "ALSA lib confmisc.c:1334:(snd_func_refer) error evaluating name\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n",
            "ALSA lib conf.c:5701:(snd_config_expand) Evaluate error: No such file or directory\n",
            "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM default\n",
            "2024-01-16 07:16:18.548460: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-01-16 07:16:18.548517: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-01-16 07:16:18.550207: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-01-16 07:16:19.673279: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "INFO:numexpr.utils:NumExpr defaulting to 2 threads.\n",
            "INFO:donkeycar.config:loading config file: ./config.py\n",
            "INFO:donkeycar.config:loading personal config over-rides from myconfig.py\n",
            "INFO:donkeycar.parts.datastore_v2:Found datastore at /content/mycar/data/tub_49_24-01-13\n",
            "INFO:donkeycar.parts.datastore_v2:Using last catalog /content/mycar/data/tub_49_24-01-13/catalog_6.catalog\n",
            "making movie tub_49_24-01-13.mp4 from 1999 images\n",
            "Moviepy - Building video tub_49_24-01-13.mp4.\n",
            "Moviepy - Writing video tub_49_24-01-13.mp4\n",
            "\n",
            "Moviepy - Done !\n",
            "Moviepy - video ready tub_49_24-01-13.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download this movie"
      ],
      "metadata": {
        "id": "4d0ZP9JMESFC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download(f\"{tub_name}.mp4\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Ca2ON1a5ERxU",
        "outputId": "1b7eec02-fd8f-4376-c89b-47ccf070d2ac"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_26539a15-b245-43fc-95a0-f04717032a07\", \"tub_49_24-01-13.mp4\", 2657329)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3Ya8qEUAfOv"
      },
      "source": [
        "## Train your model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edH3xO_AVWXu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b174fc9b-3ae6-433d-fb94-e75c7d378194"
      },
      "source": [
        "%cd /content/mycar\n",
        "\n",
        "model_name = \"model1\"\n",
        "\n",
        "!donkey train --tub ./data/{tub_name} --model models/{model_name}"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/mycar\n",
            "________             ______                   _________              \n",
            "___  __ \\_______________  /___________  __    __  ____/_____ ________\n",
            "__  / / /  __ \\_  __ \\_  //_/  _ \\_  / / /    _  /    _  __ `/_  ___/\n",
            "_  /_/ // /_/ /  / / /  ,<  /  __/  /_/ /     / /___  / /_/ /_  /    \n",
            "/_____/ \\____//_/ /_//_/|_| \\___/_\\__, /      \\____/  \\__,_/ /_/     \n",
            "                                 /____/                              \n",
            "\n",
            "using donkey v5.0.dev3 ...\n",
            "INFO:donkeycar.config:loading config file: ./config.py\n",
            "INFO:donkeycar.config:loading personal config over-rides from ./myconfig.py\n",
            "2024-01-16 07:33:33.014099: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-01-16 07:33:33.014151: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-01-16 07:33:33.015382: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-01-16 07:33:34.051156: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "INFO:numexpr.utils:NumExpr defaulting to 2 threads.\n",
            "INFO:donkeycar.pipeline.database:Found model database /content/mycar/models/database.json\n",
            "INFO:donkeycar.utils:get_model_by_type: model type is: linear\n",
            "2024-01-16 07:33:36.436409: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "INFO:donkeycar.parts.keras:Created KerasLinear with interpreter: KerasInterpreter\n",
            "Model: \"linear\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " img_in (InputLayer)         [(None, 120, 160, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)           (None, 58, 78, 24)           1824      ['img_in[0][0]']              \n",
            "                                                                                                  \n",
            " dropout (Dropout)           (None, 58, 78, 24)           0         ['conv2d_1[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)           (None, 27, 37, 32)           19232     ['dropout[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)         (None, 27, 37, 32)           0         ['conv2d_2[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)           (None, 12, 17, 64)           51264     ['dropout_1[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)         (None, 12, 17, 64)           0         ['conv2d_3[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)           (None, 10, 15, 64)           36928     ['dropout_2[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)         (None, 10, 15, 64)           0         ['conv2d_4[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)           (None, 8, 13, 64)            36928     ['dropout_3[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)         (None, 8, 13, 64)            0         ['conv2d_5[0][0]']            \n",
            "                                                                                                  \n",
            " flattened (Flatten)         (None, 6656)                 0         ['dropout_4[0][0]']           \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 100)                  665700    ['flattened[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)         (None, 100)                  0         ['dense_1[0][0]']             \n",
            "                                                                                                  \n",
            " dense_2 (Dense)             (None, 50)                   5050      ['dropout_5[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_6 (Dropout)         (None, 50)                   0         ['dense_2[0][0]']             \n",
            "                                                                                                  \n",
            " n_outputs0 (Dense)          (None, 1)                    51        ['dropout_6[0][0]']           \n",
            "                                                                                                  \n",
            " n_outputs1 (Dense)          (None, 1)                    51        ['dropout_6[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 817028 (3.12 MB)\n",
            "Trainable params: 817028 (3.12 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "INFO:donkeycar.parts.datastore_v2:Found datastore at /content/mycar/data/tub_49_24-01-13\n",
            "INFO:donkeycar.parts.datastore_v2:Using last catalog /content/mycar/data/tub_49_24-01-13/catalog_6.catalog\n",
            "INFO:donkeycar.pipeline.types:Loading tubs from paths ['./data/tub_49_24-01-13']\n",
            "INFO:donkeycar.pipeline.training:Records # Training 5298\n",
            "INFO:donkeycar.pipeline.training:Records # Validation 1325\n",
            "INFO:donkeycar.parts.tub_v2:Closing tub ./data/tub_49_24-01-13\n",
            "INFO:donkeycar.parts.image_transformations:Creating ImageTransformations []\n",
            "INFO:donkeycar.parts.image_transformations:Creating ImageTransformations []\n",
            "INFO:donkeycar.parts.image_transformations:Creating ImageTransformations []\n",
            "INFO:donkeycar.parts.image_transformations:Creating ImageTransformations []\n",
            "INFO:donkeycar.pipeline.training:Train with image caching: True\n",
            "INFO:donkeycar.parts.keras:////////// Starting training //////////\n",
            "Epoch 1/100\n",
            "2024-01-16 07:33:38.071715: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inlinear/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1705390421.707086   20156 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.5287 - n_outputs0_loss: 0.4071 - n_outputs1_loss: 0.1216\n",
            "Epoch 1: val_loss improved from inf to 0.63460, saving model to /content/mycar/models/model1\n",
            "INFO:tensorflow:Assets written to: /content/mycar/models/model1/assets\n",
            "21/21 [==============================] - 21s 596ms/step - loss: 0.5287 - n_outputs0_loss: 0.4071 - n_outputs1_loss: 0.1216 - val_loss: 0.6346 - val_n_outputs0_loss: 0.5374 - val_n_outputs1_loss: 0.0972\n",
            "Epoch 2/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.3581 - n_outputs0_loss: 0.2563 - n_outputs1_loss: 0.1019\n",
            "Epoch 2: val_loss improved from 0.63460 to 0.26703, saving model to /content/mycar/models/model1\n",
            "INFO:tensorflow:Assets written to: /content/mycar/models/model1/assets\n",
            "21/21 [==============================] - 8s 397ms/step - loss: 0.3581 - n_outputs0_loss: 0.2563 - n_outputs1_loss: 0.1019 - val_loss: 0.2670 - val_n_outputs0_loss: 0.1848 - val_n_outputs1_loss: 0.0823\n",
            "Epoch 3/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.1900 - n_outputs0_loss: 0.1167 - n_outputs1_loss: 0.0733\n",
            "Epoch 3: val_loss improved from 0.26703 to 0.18489, saving model to /content/mycar/models/model1\n",
            "INFO:tensorflow:Assets written to: /content/mycar/models/model1/assets\n",
            "21/21 [==============================] - 11s 537ms/step - loss: 0.1900 - n_outputs0_loss: 0.1167 - n_outputs1_loss: 0.0733 - val_loss: 0.1849 - val_n_outputs0_loss: 0.1053 - val_n_outputs1_loss: 0.0796\n",
            "Epoch 4/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.1462 - n_outputs0_loss: 0.0862 - n_outputs1_loss: 0.0599\n",
            "Epoch 4: val_loss improved from 0.18489 to 0.11760, saving model to /content/mycar/models/model1\n",
            "INFO:tensorflow:Assets written to: /content/mycar/models/model1/assets\n",
            "21/21 [==============================] - 11s 524ms/step - loss: 0.1462 - n_outputs0_loss: 0.0862 - n_outputs1_loss: 0.0599 - val_loss: 0.1176 - val_n_outputs0_loss: 0.0673 - val_n_outputs1_loss: 0.0503\n",
            "Epoch 5/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.1252 - n_outputs0_loss: 0.0747 - n_outputs1_loss: 0.0505\n",
            "Epoch 5: val_loss improved from 0.11760 to 0.08975, saving model to /content/mycar/models/model1\n",
            "INFO:tensorflow:Assets written to: /content/mycar/models/model1/assets\n",
            "21/21 [==============================] - 7s 350ms/step - loss: 0.1252 - n_outputs0_loss: 0.0747 - n_outputs1_loss: 0.0505 - val_loss: 0.0898 - val_n_outputs0_loss: 0.0544 - val_n_outputs1_loss: 0.0353\n",
            "Epoch 6/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.1155 - n_outputs0_loss: 0.0711 - n_outputs1_loss: 0.0445\n",
            "Epoch 6: val_loss improved from 0.08975 to 0.08856, saving model to /content/mycar/models/model1\n",
            "INFO:tensorflow:Assets written to: /content/mycar/models/model1/assets\n",
            "21/21 [==============================] - 8s 403ms/step - loss: 0.1155 - n_outputs0_loss: 0.0711 - n_outputs1_loss: 0.0445 - val_loss: 0.0886 - val_n_outputs0_loss: 0.0525 - val_n_outputs1_loss: 0.0361\n",
            "Epoch 7/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.1139 - n_outputs0_loss: 0.0713 - n_outputs1_loss: 0.0426\n",
            "Epoch 7: val_loss improved from 0.08856 to 0.08319, saving model to /content/mycar/models/model1\n",
            "INFO:tensorflow:Assets written to: /content/mycar/models/model1/assets\n",
            "21/21 [==============================] - 9s 444ms/step - loss: 0.1139 - n_outputs0_loss: 0.0713 - n_outputs1_loss: 0.0426 - val_loss: 0.0832 - val_n_outputs0_loss: 0.0532 - val_n_outputs1_loss: 0.0300\n",
            "Epoch 8/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.1026 - n_outputs0_loss: 0.0624 - n_outputs1_loss: 0.0402\n",
            "Epoch 8: val_loss improved from 0.08319 to 0.06844, saving model to /content/mycar/models/model1\n",
            "INFO:tensorflow:Assets written to: /content/mycar/models/model1/assets\n",
            "21/21 [==============================] - 7s 357ms/step - loss: 0.1026 - n_outputs0_loss: 0.0624 - n_outputs1_loss: 0.0402 - val_loss: 0.0684 - val_n_outputs0_loss: 0.0406 - val_n_outputs1_loss: 0.0279\n",
            "Epoch 9/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.0925 - n_outputs0_loss: 0.0535 - n_outputs1_loss: 0.0390\n",
            "Epoch 9: val_loss improved from 0.06844 to 0.06379, saving model to /content/mycar/models/model1\n",
            "INFO:tensorflow:Assets written to: /content/mycar/models/model1/assets\n",
            "21/21 [==============================] - 9s 440ms/step - loss: 0.0925 - n_outputs0_loss: 0.0535 - n_outputs1_loss: 0.0390 - val_loss: 0.0638 - val_n_outputs0_loss: 0.0389 - val_n_outputs1_loss: 0.0249\n",
            "Epoch 10/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.0906 - n_outputs0_loss: 0.0524 - n_outputs1_loss: 0.0382\n",
            "Epoch 10: val_loss did not improve from 0.06379\n",
            "21/21 [==============================] - 4s 218ms/step - loss: 0.0906 - n_outputs0_loss: 0.0524 - n_outputs1_loss: 0.0382 - val_loss: 0.0923 - val_n_outputs0_loss: 0.0649 - val_n_outputs1_loss: 0.0274\n",
            "Epoch 11/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.0906 - n_outputs0_loss: 0.0536 - n_outputs1_loss: 0.0370\n",
            "Epoch 11: val_loss improved from 0.06379 to 0.05765, saving model to /content/mycar/models/model1\n",
            "INFO:tensorflow:Assets written to: /content/mycar/models/model1/assets\n",
            "21/21 [==============================] - 9s 440ms/step - loss: 0.0906 - n_outputs0_loss: 0.0536 - n_outputs1_loss: 0.0370 - val_loss: 0.0576 - val_n_outputs0_loss: 0.0326 - val_n_outputs1_loss: 0.0251\n",
            "Epoch 12/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.0802 - n_outputs0_loss: 0.0451 - n_outputs1_loss: 0.0351\n",
            "Epoch 12: val_loss did not improve from 0.05765\n",
            "21/21 [==============================] - 5s 232ms/step - loss: 0.0802 - n_outputs0_loss: 0.0451 - n_outputs1_loss: 0.0351 - val_loss: 0.0591 - val_n_outputs0_loss: 0.0344 - val_n_outputs1_loss: 0.0248\n",
            "Epoch 13/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.0791 - n_outputs0_loss: 0.0448 - n_outputs1_loss: 0.0343\n",
            "Epoch 13: val_loss improved from 0.05765 to 0.05422, saving model to /content/mycar/models/model1\n",
            "INFO:tensorflow:Assets written to: /content/mycar/models/model1/assets\n",
            "21/21 [==============================] - 9s 463ms/step - loss: 0.0791 - n_outputs0_loss: 0.0448 - n_outputs1_loss: 0.0343 - val_loss: 0.0542 - val_n_outputs0_loss: 0.0323 - val_n_outputs1_loss: 0.0219\n",
            "Epoch 14/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.0724 - n_outputs0_loss: 0.0415 - n_outputs1_loss: 0.0309\n",
            "Epoch 14: val_loss improved from 0.05422 to 0.05270, saving model to /content/mycar/models/model1\n",
            "INFO:tensorflow:Assets written to: /content/mycar/models/model1/assets\n",
            "21/21 [==============================] - 7s 352ms/step - loss: 0.0724 - n_outputs0_loss: 0.0415 - n_outputs1_loss: 0.0309 - val_loss: 0.0527 - val_n_outputs0_loss: 0.0314 - val_n_outputs1_loss: 0.0213\n",
            "Epoch 15/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.0716 - n_outputs0_loss: 0.0393 - n_outputs1_loss: 0.0324\n",
            "Epoch 15: val_loss did not improve from 0.05270\n",
            "21/21 [==============================] - 6s 306ms/step - loss: 0.0716 - n_outputs0_loss: 0.0393 - n_outputs1_loss: 0.0324 - val_loss: 0.0535 - val_n_outputs0_loss: 0.0319 - val_n_outputs1_loss: 0.0217\n",
            "Epoch 16/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.0733 - n_outputs0_loss: 0.0407 - n_outputs1_loss: 0.0326\n",
            "Epoch 16: val_loss did not improve from 0.05270\n",
            "21/21 [==============================] - 6s 284ms/step - loss: 0.0733 - n_outputs0_loss: 0.0407 - n_outputs1_loss: 0.0326 - val_loss: 0.0548 - val_n_outputs0_loss: 0.0309 - val_n_outputs1_loss: 0.0239\n",
            "Epoch 17/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.0712 - n_outputs0_loss: 0.0405 - n_outputs1_loss: 0.0307\n",
            "Epoch 17: val_loss did not improve from 0.05270\n",
            "21/21 [==============================] - 7s 325ms/step - loss: 0.0712 - n_outputs0_loss: 0.0405 - n_outputs1_loss: 0.0307 - val_loss: 0.0632 - val_n_outputs0_loss: 0.0336 - val_n_outputs1_loss: 0.0296\n",
            "Epoch 18/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.0710 - n_outputs0_loss: 0.0411 - n_outputs1_loss: 0.0299\n",
            "Epoch 18: val_loss improved from 0.05270 to 0.04838, saving model to /content/mycar/models/model1\n",
            "INFO:tensorflow:Assets written to: /content/mycar/models/model1/assets\n",
            "21/21 [==============================] - 8s 414ms/step - loss: 0.0710 - n_outputs0_loss: 0.0411 - n_outputs1_loss: 0.0299 - val_loss: 0.0484 - val_n_outputs0_loss: 0.0276 - val_n_outputs1_loss: 0.0208\n",
            "Epoch 19/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.0650 - n_outputs0_loss: 0.0372 - n_outputs1_loss: 0.0278\n",
            "Epoch 19: val_loss improved from 0.04838 to 0.04768, saving model to /content/mycar/models/model1\n",
            "INFO:tensorflow:Assets written to: /content/mycar/models/model1/assets\n",
            "21/21 [==============================] - 10s 499ms/step - loss: 0.0650 - n_outputs0_loss: 0.0372 - n_outputs1_loss: 0.0278 - val_loss: 0.0477 - val_n_outputs0_loss: 0.0288 - val_n_outputs1_loss: 0.0189\n",
            "Epoch 20/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.0656 - n_outputs0_loss: 0.0380 - n_outputs1_loss: 0.0277\n",
            "Epoch 20: val_loss did not improve from 0.04768\n",
            "21/21 [==============================] - 5s 228ms/step - loss: 0.0656 - n_outputs0_loss: 0.0380 - n_outputs1_loss: 0.0277 - val_loss: 0.0571 - val_n_outputs0_loss: 0.0372 - val_n_outputs1_loss: 0.0199\n",
            "Epoch 21/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.0638 - n_outputs0_loss: 0.0362 - n_outputs1_loss: 0.0276\n",
            "Epoch 21: val_loss did not improve from 0.04768\n",
            "21/21 [==============================] - 6s 309ms/step - loss: 0.0638 - n_outputs0_loss: 0.0362 - n_outputs1_loss: 0.0276 - val_loss: 0.0572 - val_n_outputs0_loss: 0.0336 - val_n_outputs1_loss: 0.0235\n",
            "Epoch 22/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.0667 - n_outputs0_loss: 0.0396 - n_outputs1_loss: 0.0271\n",
            "Epoch 22: val_loss improved from 0.04768 to 0.04506, saving model to /content/mycar/models/model1\n",
            "INFO:tensorflow:Assets written to: /content/mycar/models/model1/assets\n",
            "21/21 [==============================] - 8s 406ms/step - loss: 0.0667 - n_outputs0_loss: 0.0396 - n_outputs1_loss: 0.0271 - val_loss: 0.0451 - val_n_outputs0_loss: 0.0269 - val_n_outputs1_loss: 0.0181\n",
            "Epoch 23/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.0586 - n_outputs0_loss: 0.0337 - n_outputs1_loss: 0.0249\n",
            "Epoch 23: val_loss improved from 0.04506 to 0.04233, saving model to /content/mycar/models/model1\n",
            "INFO:tensorflow:Assets written to: /content/mycar/models/model1/assets\n",
            "21/21 [==============================] - 8s 398ms/step - loss: 0.0586 - n_outputs0_loss: 0.0337 - n_outputs1_loss: 0.0249 - val_loss: 0.0423 - val_n_outputs0_loss: 0.0246 - val_n_outputs1_loss: 0.0177\n",
            "Epoch 24/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.0586 - n_outputs0_loss: 0.0339 - n_outputs1_loss: 0.0247\n",
            "Epoch 24: val_loss did not improve from 0.04233\n",
            "21/21 [==============================] - 5s 252ms/step - loss: 0.0586 - n_outputs0_loss: 0.0339 - n_outputs1_loss: 0.0247 - val_loss: 0.0432 - val_n_outputs0_loss: 0.0251 - val_n_outputs1_loss: 0.0181\n",
            "Epoch 25/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.0574 - n_outputs0_loss: 0.0327 - n_outputs1_loss: 0.0247\n",
            "Epoch 25: val_loss improved from 0.04233 to 0.03939, saving model to /content/mycar/models/model1\n",
            "INFO:tensorflow:Assets written to: /content/mycar/models/model1/assets\n",
            "21/21 [==============================] - 9s 453ms/step - loss: 0.0574 - n_outputs0_loss: 0.0327 - n_outputs1_loss: 0.0247 - val_loss: 0.0394 - val_n_outputs0_loss: 0.0222 - val_n_outputs1_loss: 0.0172\n",
            "Epoch 26/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.0551 - n_outputs0_loss: 0.0319 - n_outputs1_loss: 0.0232\n",
            "Epoch 26: val_loss improved from 0.03939 to 0.03863, saving model to /content/mycar/models/model1\n",
            "INFO:tensorflow:Assets written to: /content/mycar/models/model1/assets\n",
            "21/21 [==============================] - 9s 451ms/step - loss: 0.0551 - n_outputs0_loss: 0.0319 - n_outputs1_loss: 0.0232 - val_loss: 0.0386 - val_n_outputs0_loss: 0.0221 - val_n_outputs1_loss: 0.0166\n",
            "Epoch 27/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.0581 - n_outputs0_loss: 0.0339 - n_outputs1_loss: 0.0242\n",
            "Epoch 27: val_loss did not improve from 0.03863\n",
            "21/21 [==============================] - 5s 229ms/step - loss: 0.0581 - n_outputs0_loss: 0.0339 - n_outputs1_loss: 0.0242 - val_loss: 0.0402 - val_n_outputs0_loss: 0.0239 - val_n_outputs1_loss: 0.0164\n",
            "Epoch 28/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.0569 - n_outputs0_loss: 0.0323 - n_outputs1_loss: 0.0246\n",
            "Epoch 28: val_loss did not improve from 0.03863\n",
            "21/21 [==============================] - 8s 382ms/step - loss: 0.0569 - n_outputs0_loss: 0.0323 - n_outputs1_loss: 0.0246 - val_loss: 0.0550 - val_n_outputs0_loss: 0.0342 - val_n_outputs1_loss: 0.0208\n",
            "Epoch 29/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.0557 - n_outputs0_loss: 0.0325 - n_outputs1_loss: 0.0233\n",
            "Epoch 29: val_loss did not improve from 0.03863\n",
            "21/21 [==============================] - 4s 212ms/step - loss: 0.0557 - n_outputs0_loss: 0.0325 - n_outputs1_loss: 0.0233 - val_loss: 0.0434 - val_n_outputs0_loss: 0.0272 - val_n_outputs1_loss: 0.0162\n",
            "Epoch 30/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.0547 - n_outputs0_loss: 0.0323 - n_outputs1_loss: 0.0224\n",
            "Epoch 30: val_loss did not improve from 0.03863\n",
            "21/21 [==============================] - 5s 258ms/step - loss: 0.0547 - n_outputs0_loss: 0.0323 - n_outputs1_loss: 0.0224 - val_loss: 0.0462 - val_n_outputs0_loss: 0.0291 - val_n_outputs1_loss: 0.0170\n",
            "Epoch 31/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.0565 - n_outputs0_loss: 0.0336 - n_outputs1_loss: 0.0228\n",
            "Epoch 31: val_loss improved from 0.03863 to 0.03565, saving model to /content/mycar/models/model1\n",
            "INFO:tensorflow:Assets written to: /content/mycar/models/model1/assets\n",
            "21/21 [==============================] - 9s 436ms/step - loss: 0.0565 - n_outputs0_loss: 0.0336 - n_outputs1_loss: 0.0228 - val_loss: 0.0357 - val_n_outputs0_loss: 0.0193 - val_n_outputs1_loss: 0.0164\n",
            "Epoch 32/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.0520 - n_outputs0_loss: 0.0298 - n_outputs1_loss: 0.0222\n",
            "Epoch 32: val_loss did not improve from 0.03565\n",
            "21/21 [==============================] - 5s 264ms/step - loss: 0.0520 - n_outputs0_loss: 0.0298 - n_outputs1_loss: 0.0222 - val_loss: 0.0432 - val_n_outputs0_loss: 0.0270 - val_n_outputs1_loss: 0.0161\n",
            "Epoch 33/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.0492 - n_outputs0_loss: 0.0289 - n_outputs1_loss: 0.0203\n",
            "Epoch 33: val_loss improved from 0.03565 to 0.03536, saving model to /content/mycar/models/model1\n",
            "INFO:tensorflow:Assets written to: /content/mycar/models/model1/assets\n",
            "21/21 [==============================] - 9s 430ms/step - loss: 0.0492 - n_outputs0_loss: 0.0289 - n_outputs1_loss: 0.0203 - val_loss: 0.0354 - val_n_outputs0_loss: 0.0212 - val_n_outputs1_loss: 0.0142\n",
            "Epoch 34/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.0490 - n_outputs0_loss: 0.0295 - n_outputs1_loss: 0.0194\n",
            "Epoch 34: val_loss did not improve from 0.03536\n",
            "21/21 [==============================] - 5s 249ms/step - loss: 0.0490 - n_outputs0_loss: 0.0295 - n_outputs1_loss: 0.0194 - val_loss: 0.0424 - val_n_outputs0_loss: 0.0274 - val_n_outputs1_loss: 0.0150\n",
            "Epoch 35/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.0472 - n_outputs0_loss: 0.0271 - n_outputs1_loss: 0.0201\n",
            "Epoch 35: val_loss improved from 0.03536 to 0.03522, saving model to /content/mycar/models/model1\n",
            "INFO:tensorflow:Assets written to: /content/mycar/models/model1/assets\n",
            "21/21 [==============================] - 9s 454ms/step - loss: 0.0472 - n_outputs0_loss: 0.0271 - n_outputs1_loss: 0.0201 - val_loss: 0.0352 - val_n_outputs0_loss: 0.0211 - val_n_outputs1_loss: 0.0141\n",
            "Epoch 36/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.0453 - n_outputs0_loss: 0.0263 - n_outputs1_loss: 0.0190\n",
            "Epoch 36: val_loss improved from 0.03522 to 0.03221, saving model to /content/mycar/models/model1\n",
            "INFO:tensorflow:Assets written to: /content/mycar/models/model1/assets\n",
            "21/21 [==============================] - 9s 428ms/step - loss: 0.0453 - n_outputs0_loss: 0.0263 - n_outputs1_loss: 0.0190 - val_loss: 0.0322 - val_n_outputs0_loss: 0.0184 - val_n_outputs1_loss: 0.0138\n",
            "Epoch 37/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.0439 - n_outputs0_loss: 0.0256 - n_outputs1_loss: 0.0183\n",
            "Epoch 37: val_loss did not improve from 0.03221\n",
            "21/21 [==============================] - 5s 235ms/step - loss: 0.0439 - n_outputs0_loss: 0.0256 - n_outputs1_loss: 0.0183 - val_loss: 0.0344 - val_n_outputs0_loss: 0.0209 - val_n_outputs1_loss: 0.0134\n",
            "Epoch 38/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.0459 - n_outputs0_loss: 0.0276 - n_outputs1_loss: 0.0183\n",
            "Epoch 38: val_loss did not improve from 0.03221\n",
            "21/21 [==============================] - 8s 400ms/step - loss: 0.0459 - n_outputs0_loss: 0.0276 - n_outputs1_loss: 0.0183 - val_loss: 0.0350 - val_n_outputs0_loss: 0.0222 - val_n_outputs1_loss: 0.0128\n",
            "Epoch 39/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.0432 - n_outputs0_loss: 0.0246 - n_outputs1_loss: 0.0186\n",
            "Epoch 39: val_loss did not improve from 0.03221\n",
            "21/21 [==============================] - 5s 222ms/step - loss: 0.0432 - n_outputs0_loss: 0.0246 - n_outputs1_loss: 0.0186 - val_loss: 0.0352 - val_n_outputs0_loss: 0.0221 - val_n_outputs1_loss: 0.0132\n",
            "Epoch 40/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.0426 - n_outputs0_loss: 0.0250 - n_outputs1_loss: 0.0176\n",
            "Epoch 40: val_loss did not improve from 0.03221\n",
            "21/21 [==============================] - 5s 265ms/step - loss: 0.0426 - n_outputs0_loss: 0.0250 - n_outputs1_loss: 0.0176 - val_loss: 0.0337 - val_n_outputs0_loss: 0.0207 - val_n_outputs1_loss: 0.0130\n",
            "Epoch 41/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.0444 - n_outputs0_loss: 0.0267 - n_outputs1_loss: 0.0177\n",
            "Epoch 41: val_loss did not improve from 0.03221\n",
            "21/21 [==============================] - 7s 317ms/step - loss: 0.0444 - n_outputs0_loss: 0.0267 - n_outputs1_loss: 0.0177 - val_loss: 0.0365 - val_n_outputs0_loss: 0.0238 - val_n_outputs1_loss: 0.0127\n",
            "INFO:donkeycar.parts.keras:////////// Finished training in: 0:05:11.869706 //////////\n",
            "INFO:donkeycar.parts.interpreter:Convert model /content/mycar/models/model1 to TFLite /content/mycar/models/model1.tflite\n",
            "INFO:tensorflow:Assets written to: /tmp/tmpyztf8ckx/assets\n",
            "2024-01-16 07:38:52.349198: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
            "2024-01-16 07:38:52.349239: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
            "Summary on the non-converted ops:\n",
            "---------------------------------\n",
            " * Accepted dialects: tfl, builtin, func\n",
            " * Non-Converted Ops: 19, Total Ops 32, % non-converted = 59.38 %\n",
            " * 19 ARITH ops\n",
            "\n",
            "- arith.constant:   19 occurrences  (f32: 18, i32: 1)\n",
            "\n",
            "\n",
            "\n",
            "  (f32: 5)\n",
            "  (f32: 4)\n",
            "  (f32: 1)\n",
            "INFO:donkeycar.parts.interpreter:TFLite conversion done.\n",
            "INFO:donkeycar.pipeline.database:Writing database file: /content/mycar/models/database.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Quiz\n",
        "1. How many records are used for training?\n",
        "2. How many records are used for validation?\n",
        "3. Does the sum of this number adds up to the number of images in the dataset?\n",
        "4. What is the final lost value?\n",
        "5. How long does this training last?\n",
        "6. How many epoches in this training?\n",
        "7. How many steps in this epoch?\n",
        "8. What's the value of `MAX_EPOCHS` in `myconfig.py`?\n",
        "9. Why the training stop before it reaches the 100th epoch?"
      ],
      "metadata": {
        "id": "HeHjt60xKphz"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXzn1noJz5MQ"
      },
      "source": [
        "Check if the model is generated\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5b9vJV4EzlO8"
      },
      "source": [
        "!ls -alh /content/mycar/models/{model_name}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AixQrFy_z3vv"
      },
      "source": [
        "%cd /content/mycar/models/{model_name}\n",
        "\n",
        "import glob\n",
        "file = glob.glob(\"*.png\")\n",
        "\n",
        "from IPython.display import Image\n",
        "Image(file[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BEOJYH601O0"
      },
      "source": [
        "## Copy the trained model back to Donkey Car (Pi)\n",
        "\n",
        "Once the training is complete on colab, download the model file under /content/mycar/models/ folder location."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtvyJpOdocjb"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('./mypilot.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7AIY6yBOCM-"
      },
      "source": [
        "Alternatively, you can copy the model back to Google Drive too"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Dim4fCpOBo9"
      },
      "source": [
        "!cp /content/mycar/models/mypilot.h5 /content/drive/My\\ Drive/mycar/models/mypilot.h5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpkOVzh86omO"
      },
      "source": [
        "### Copy the file from your PC or Mac to the Raspberry Pi using Filezilla or scp command.\n",
        "\n",
        "```\n",
        "sftp pi@raspberry.local\n",
        "cd mycar/models\n",
        "put mypilot.h5\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfERkGy821Xy"
      },
      "source": [
        "## Start Autopilot on Pi\n",
        "\n",
        "\n",
        "```bash\n",
        "cd ~/mycar\n",
        "python manage.py drive --model models/mypilot.h5 --js\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Changing training parameters"
      ],
      "metadata": {
        "id": "7vBkLcqCKMHv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Change number of epoch"
      ],
      "metadata": {
        "id": "7itOFJ_8KP8N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Edit `myconfig.py`\n",
        "2. Change `MAX_EPOCHS` to 5, 10 , 20\n",
        "3. Training the model again by executing the training script above\n",
        "4. What is `MAX_EPOCHS` used for?\n",
        "5. Why do we want to change `MAX_EPOCHS`?"
      ],
      "metadata": {
        "id": "ZgnRGiMtLSHv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Change TRAIN_FILTER"
      ],
      "metadata": {
        "id": "jy5ax0YlKTyq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Change TRAIN_FILTER in `myconfig.py` to > 0.1 and check the number of images used for training and validation"
      ],
      "metadata": {
        "id": "CCnJoXqLKeDo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Change Batch Size"
      ],
      "metadata": {
        "id": "J7Nn7rjkLVRb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Edit `myconfig.py`\n",
        "2. Change `BATCH_SIZE` to 256\n",
        "3. Training the model again by executing the training script above\n",
        "4. Does the training go faster? Why?\n"
      ],
      "metadata": {
        "id": "Zv_4oluqLXa4"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X93SodzAv9hV"
      },
      "source": [
        "## Bonus - Salient Object Visualization"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imageio-ffmpeg\n"
      ],
      "metadata": {
        "id": "1nGatrwZiTEt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKI37gVrv9Q8"
      },
      "source": [
        "%cd /content/mycar\n",
        "!donkey makemovie --tub data/{tub_name} --model models/mypilot.h5 --type linear --salient"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcUrgOq_pePV"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "%cd /content/mycar\n",
        "!ls -ahl\n",
        "files.download('tub_movie.mp4')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}